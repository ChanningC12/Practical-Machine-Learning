Practical Machine Learning - Week 2
============================================================

# Principal Components Analysis
```{r include=FALSE}
library(caret)
library(kernlab)
```

```{r}
data(spam)
inTrain = createDataPartition(y=spam$type,p=0.7,list=F)
training = spam[inTrain,]
testing = spam[-inTrain,]
dim(training)
dim(testing)
```

##### Correlated Predictors
```{r}
M = abs(cor(training[,-58]))
diag(M) <- 0 # predictors with themselves
which(M>0.8,arr.ind=T)
```

```{r}
names(spam)[c(34,32)]
plot(spam[,34],spam[,32])
```

### Principal Component Idea
- Might not need every predictor
- A weighted combination of predictiors might be better
- We should pick this combination to capture the "most information" possible

```{r}
smallSpam <- spam[,c(34,32)]
prComp <- prcomp(smallSpam)
plot(prComp$x[,1],prComp$x[,2])
```

##### Rotation matrix
```{r}
prComp$rotation
```

##### PCA with caret
```{r}
preProc = preProcess(log10(spam[,-58]+1),method="pca",pcaComp=2)
spamPC = predict(preProc,log10(spam[,-58]+1))
typeColor = ((spam$type=="spam")*1+1)
plot(spamPC[,1],spamPC[,2],col=typeColor)
```

##### PCA reduces the number of predictors while keep the accuracy strong
```{r}
trainPC = predict(preProc,log10(training[,-58]+1))
modelFit = train(training$type~.,method="glm",data=trainPC)
testPC = predict(preProc,log10(testing[,-58]+1)) # must use same prediction process on testing data
confusionMatrix(testing$type,predict(modelFit,testPC))
```

##### Alternative
```{r}
modelFit = train(training$type~.,method="glm",preProcess="pca",data=training)
summary(modelFit)
confusionMatrix(testing$type,predict(modelFit,testing))
```


# Fitting a regression model
```{r}
library(caret)
data(faithful)
set.seed(333)
inTrain = createDataPartition(y=faithful$waiting,p=0.5,list=F)
trainFaith = faithful[inTrain,]
testFaith <- faithful[-inTrain,]
head(trainFaith)
```

```{r}
lm1 = lm(eruptions~waiting,data=trainFaith)
summary(lm1)
predict(lm1,newdata=testFaith)
```

##### Get training / testing errors
```{r}
# Calculate RMSE on training
sqrt(sum((lm1$fitted-trainFaith$eruptions)^2))
# Calculate RMSE on test
sqrt(sum((predict(lm1,newdata=testFaith)-testFaith$eruptions)^2))
```

##### Same process with caret
```{r}
modFit = train(eruptions~waiting,data=trainFaith,method="lm")
summary(modFit$finalModel)
```

# Predicting with regression with multiple covariates
```{r}
library(ISLR)
library(ggplot2)
library(caret)
data(Wage)
Wage = subset(Wage,select=-c(logwage))
summary(Wage)
```

```{r}
inTrain = createDataPartition(y=Wage$wage,p=0.7,list=F)
training = Wage[inTrain,]
testing = Wage[-inTrain,]
dim(training)
dim(testing)
```

##### plot age versus wage
```{r}
qplot(age,wage,data=training)
qplot(age,wage,data=training,colour=jobclass)
qplot(age,wage,data=training,colour=education)
```

##### Fit a linear model
```{r}
# by default, factor variables will become indicators
modFit = train(wage~age+jobclass+ducation,method="lm",data-training) 
finMod = modFit$finalModel
print(modFit)
```

##### Diagnostics
```{r}
plot(finMod,1,pch=19,cex=0.5,col="#00000010")
```

##### Color by variables not used in the model
```{r}
qplot(finMod$fitted,finMod$residuals,colour=race,data=training)
```

##### Plot by index
```{r}
plot(finMod$residuals,pch=19)
```

##### Predicted versus truth in test set
```{r}
pred = predict(modFit,testing)
qplot(wage,pred,colour=year,data=testing)
````





















































